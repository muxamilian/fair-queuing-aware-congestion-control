\documentclass[conference]{IEEEtran}
% \IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{subfig}
\usepackage{tabularx}
\begin{document}

\title{Fair Queuing Aware Congestion Control}

\author{\IEEEauthorblockN{Maximilian Bachl}
\IEEEauthorblockA{{\scriptsize \url{https://github.com/muxamilian/fair-queuing-aware-congestion-control}}}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
}

\maketitle

\begin{abstract}
Fair queuing is becoming increasingly prevalent in the internet and has been shown to improve performance in many circumstances. 
Performance could be improved even more if endpoints could detect the presence of fair queuing on a certain path and adjust their congestion control accordingly. 
If fair queuing is detected, the congestion control would not have to take cross traffic into account, which allows for more flexibility. 
In this paper, we develop the first algorithm that continuously checks if fair queuing is present on a path. 
When fair queuing is detected, a different congestion control is chosen, which results in reduced latency. 
Unlike an algorithm proposed in a previous paper of us, the approach presented here does not only detect the presence of fair queuing once at flow startup but it does so continuously. 
\end{abstract}

% \begin{IEEEkeywords}
% component, formatting, style, styling, insert
% \end{IEEEkeywords}

\section{Background}

When different applications send packets on the internet, one application can send more than the other and thus take unfairly take a larger share of bandwidth. 
This can result in unfairness and bad user experience. Several different approaches have been proposed to address this \cite{brown_future_2020,ware_beyond_2019} : One is to make sure every network flow is ``well-behaved'' (also known as TCP friendly)
Another one is to enforce fairness at switches and routers, called ``fair queuing'' or ``flow queuing'' \cite{nagle_packet_1985}. 

While fair queuing was proposed decades ago, it only gained popularity in the last couple of years because of implementations in the Linux kernel \cite{dumazet_pkt_sched_2013,hoeiland-joergensen_flow_2018}. 
Applications can benefit from increasing deployment of fair queuing: It makes sure that not the most aggressive one wins. 
It would be even better if applications could know if the connection they're sending on is managed by fair queuing. Then they could be sure that the can use a common congestion control mechanism, while not bothering or being bothered by other network flows.
We proposed the first such approach in previous work \cite{bachl_detecting_2021} but our previous approach had some shortcomings upon which we improve in this paper. 

Our approach is a congestion control mechanism which also performs measurements to determine if there is fair queuing. 
This approach of performing measurements in congestion control became popular in the last couple of years and was already followed by \cite{cardwell_bbr_2016,dong_pcc_2015,goyal_elasticity_2020,hayes_online_2020}.

\section{Introduction}

In our previous work we proposed a technique which determines the presence of fair queuing at flow startup \cite{bachl_detecting_2021}, which worked as follows: 
If fair queuing is successfully detected at flow startup, a congestion control was used, which aimed to keep queuing delay low (delay-based congestion control). 
While this delay-based congestion control achieved high throughput and low delay, it was vulnerable to be outcompeted by other network flows sending more aggressively, such as \cite{cardwell_bbr_2016,dong_pcc_2015,noauthor_cubic_nodate}, 
similar to the Vegas congestion control algorithm \cite{brakmo_tcp_1995}.
This means that our delay-based congestion control performed well but only when it wouldn't have to compete with other flows. Thus is only used if fair queuing is detected. 
If it is detected that there is no fair queuing, our approach uses a more aggressive congestion control (specifically PCC \cite{dong_pcc_2015}), which can compete better with other network flows,
but doesn't keep delay as low as our delay-based congestion control. 

While our previous approach had high detection accuracy (98\%), it also had some limitations:
\begin{itemize}
    \item It would \textbf{only} detect fair queuing at \textbf{flow startup}. 
    But if the bottleneck link changes during a flow, it could be that the previous bottleneck had fair queuing while the new one doesn't. This wouldn't have been detected. 
    \item It would detect fair queuing only after filling the queue at the bottleneck completely, \textbf{causing packet loss}. 
\end{itemize}

We would thus like to have an approach which 
\begin{itemize}
    \item \textbf{continuously checks} for the presence or absence of fair queuing, not only at flow startup. 
    \item \textbf{doesn't cause packet loss} while trying to determine if there is fair queuing or not. 
    \item can be \textbf{transparently used} on top of any congestion control algorithm. 
\end{itemize} 

\section{Concept}

% \begin{figure}
% \centering
% \subfloat[\footnotesize Sending rate]{\includegraphics[width=0.33\columnwidth]{{"figures/fq_illustration_throughput"}.pdf}
% \label{fig:throughput}}
% \subfloat[\footnotesize Receiving rate\\(no fair queuing)]{\includegraphics[width=0.33\columnwidth]{{"figures/fq_illustration_goodput_no_fq"}.pdf}
% \label{fig:goodput_no_fq}}
% \subfloat[\footnotesize Receiving rate\\(fair queuing)]{\includegraphics[width=0.33\columnwidth]{{"figures/fq_illustration_goodput_fq"}.pdf}
% \label{fig:goodput_fq}}
% \caption{An example illustrating our proposed flow startup mechanism. Figure \ref{fig:throughput} shows the sending rate, \ref{fig:goodput_no_fq} the receiving rate in case there's no fair queuing and \ref{fig:goodput_fq} the receiving rate if there is fair queuing.}
% \label{fig:illustration}
% \end{figure}

\begin{figure}
\centering
\subfloat[\footnotesize Sending rate at the sender (fair queuing)]{\includegraphics[width=\columnwidth]{{"figures/bw_server_fq"}.pdf}
\label{fig:sender}}\\
\subfloat[\footnotesize Receiving rate at the receiver (fair queuing)]{\includegraphics[width=\columnwidth]{{"figures/bw_client_fq"}.pdf}
\label{fig:receiver}}
\caption{Figure \ref{fig:sender} shows the sending rate, \ref{fig:receiver} the receiving rate in case there's fair queuing. 
Around seconds 12 and 13.5, the sending rate reaches the maximum of the link -- 50 Mbit/s -- and fair queuing starts to limit the throughput of the flow that is sending more. 
Thus, in the lower figure, the dominant flow and the non-dominant flow achieve approx.~the same receiving rate even though the dominant flow sends more (dominant flow). This is the effect of fair queuing.}
\label{fig:illustration_fq}
\end{figure}

\begin{figure}
\centering
\subfloat[\footnotesize Sending rate at the sender (no fair queuing)]{\includegraphics[width=\columnwidth]{{"figures/bw_server_pfifo"}.pdf}
\label{fig:sender_pfifo}}\\
\subfloat[\footnotesize Receiving rate at the receiver (no fair queuing)]{\includegraphics[width=\columnwidth]{{"figures/bw_client_pfifo"}.pdf}
\label{fig:receiver_pfifo}}
\caption{Figure \ref{fig:sender_pfifo} shows the sending rate, \ref{fig:receiver_pfifo} the receiving rate in case there's no fair queuing. 
Even though the sender sends too much and a queue builds up, still the flow that sends more data also has a higher receiving rate. 
This is in contrast to \autoref{fig:illustration_fq}, where both flows have the same receiving rate once there is congestion at the bottleneck, thanks to fair queuing.}
\label{fig:illustration_no_fq}
\end{figure}

\section{Evaluation}

\begin{table}
\begin{tabularx}{\columnwidth}{| l | X | X | X |}
\hline
& 10 Mbit/s & 50 Mbit/s & 100 Mbit/s \\ \hline
10ms & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\%\\ \hline
50ms & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% \\ \hline
100ms & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% \\ \hline
\hline
\end{tabularx}
\caption{Detection accuracy in case there's \textbf{no fair queuing}. The average accuracy (true negative rate) is 100\%}
\label{table:no_fq}
\end{table}

\begin{table}
\begin{tabularx}{\columnwidth}{| l | X | X | X |}
\hline
& 10 Mbit/s & 50 Mbit/s & 100 Mbit/s \\ \hline
10ms & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 99\% \newline 3rd quart.: 100\%\\ \hline
50ms & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% \\ \hline
100ms & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% & Median: 100\% \newline 1st quart.: 100\% \newline 3rd quart.: 100\% \\ \hline
\hline
\end{tabularx}
\caption{Detection accuracy in case there is \textbf{fair queuing}. The average accuracy (true positive rate) is 96\%}
\label{table:fq}
\end{table}    

\section{Discussion}

\bibliographystyle{ieeetr}
\bibliography{fair-queuing-aware-congestion-control}

\end{document}
